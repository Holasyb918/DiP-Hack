# DiP: Taming Diffusion Models in Pixel Space

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

## English

### Overview

Unofficial implementation of **DiP** based on the paper:

ğŸ“„ **[DiP: Taming Diffusion Models in Pixel Space](https://arxiv.org/abs/2511.18822)**

### Key Features

- **Patch Detailer Head**: Lightweight U-Net for local texture refinement
- **Global Semantic Injection**: DiT features concatenated at U-Net bottleneck (1Ã—1)
- **Minimal Overhead**: Only +0.3% parameters over baseline DiT
- **State-of-the-art**: FID 1.79 on ImageNet 256Ã—256, 10Ã— faster than PixelFlow

### Quick Start

```python
from dip_model import DiP

# Create model
model = DiP(
    input_size=256,
    patch_size=16,
    hidden_size=1152,
    patch_depth=26,
    num_classes=1000,
)

# Forward
x = torch.randn(2, 3, 256, 256)
t = torch.randint(0, 1000, (2,))
y = torch.randint(0, 1000, (2,))
noise_pred = model(x, t, y)
```

### Requirements

```
torch
einops
timm
numpy
```

### Contact

If you have any questions or suggestions, feel free to reach out!

---

## ä¸­æ–‡

### æ¦‚è¿°

åŸºäºè®ºæ–‡çš„ **DiP** éå®˜æ–¹å®ç°ï¼š

ğŸ“„ **[DiP: Taming Diffusion Models in Pixel Space](https://arxiv.org/abs/2511.18822)**

### æ ¸å¿ƒç‰¹æ€§

- **Patch Detailer Head**ï¼šè½»é‡çº§ U-Net ç”¨äºå±€éƒ¨çº¹ç†ç»†åŒ–
- **å…¨å±€è¯­ä¹‰æ³¨å…¥**ï¼šDiT ç‰¹å¾åœ¨ U-Net bottleneck (1Ã—1) å¤„ concat
- **æå°å¼€é”€**ï¼šç›¸æ¯” DiT ä»…å¢åŠ  0.3% å‚æ•°
- **SOTA æ€§èƒ½**ï¼šImageNet 256Ã—256 FID 1.79ï¼Œæ¯” PixelFlow å¿« 10 å€

### å¿«é€Ÿå¼€å§‹

```python
from dip_model import DiP

# åˆ›å»ºæ¨¡å‹
model = DiP(
    input_size=256,
    patch_size=16,
    hidden_size=1152,
    patch_depth=26,
    num_classes=1000,
)

# å‰å‘ä¼ æ’­
x = torch.randn(2, 3, 256, 256)
t = torch.randint(0, 1000, (2,))
y = torch.randint(0, 1000, (2,))
noise_pred = model(x, t, y)
```

### ä¾èµ–

```
torch
einops
timm
numpy
```

### è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ï¼

---
